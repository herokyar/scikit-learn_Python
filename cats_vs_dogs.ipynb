{
 "metadata": {
  "name": "",
  "signature": "sha256:7be7f6f2f97e5ce121fc640b88f4bc91db7ab563bd5c0447e3e2d60c86bd9733"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Cats vs Dogs  Kaggle Competition\n",
      "#distinguish dogs from cats (semi-supervised learning- use k-means clustering to cluster images first)\n",
      "#then do logistic regression (binary classification) to classifify cats and dogs\n",
      "\n",
      "#get the dataset at :\n",
      "#https://www.kaggle.com/c/dogs-vs-cats/data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import mahotas as mh\n",
      "from mahotas.features import surf\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import *\n",
      "from sklearn.cluster import MiniBatchKMeans\n",
      "import glob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create empty list for filenames and target values (1 for cat images, 0 for dog images)\n",
      "all_instance_filenames = []\n",
      "\n",
      "all_instance_targets = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read the filenames into all_instance_filenames and all_instance_targets\n",
      "for f in glob.glob('C:/users/hasan/train/*.jpg'):\n",
      "    target = 1 if 'cat' in f else 0\n",
      "    all_instance_filenames.append(f)\n",
      "    all_instance_targets.append(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "surf_features = []\n",
      "counter = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read the images in grey color and get the features\n",
      "for f in all_instance_filenames:\n",
      "    print 'reading image:', f\n",
      "    image = mh.imread(f, as_grey=True)\n",
      "    surf_features.append(surf.surf(image)[:, 5:])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_len = int(len(all_instance_filenames)  *.6) #%60 percent for training, %40 percent for testing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_len"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "15000"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the features\n",
      "X_train_surf_features = np.concatenate(surf_features[:train_len])\n",
      "X_test_surf_features = np.concatenate(surf_features[train_len:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the labels\n",
      "y_train = all_instance_targets[:train_len]\n",
      "y_test = all_instance_targets[train_len:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#apply a k-nearest neighbors algorithm with 300 clusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_clusters = 300"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'clustering', len(X_train_surf_features), 'features'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = MiniBatchKMeans(n_clusters=n_clusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator.fit_transform(X_train_surf_features) #fit the model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###PYTHON WENT OUT OF MEMORY WHILE FITTING THE MODEL###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create training set after feature extraction stage (each image is represented by 300 features)\n",
      "X_train = []\n",
      "\n",
      "for instance in surf_features[:train_len]:\n",
      "    clusters = estimator.predict(instance)\n",
      "    features = np.bincount(clusters)\n",
      "    if len(features) < n_clusters:\n",
      "        features = np.append(features, np.zeros((1, n_clusterslen(features))))\n",
      "    X_train.append(features)\n",
      "\n",
      "    \n",
      "#create set set     \n",
      "X_test = []\n",
      "\n",
      "for instance in surf_features[train_len:]:\n",
      "    clusters = estimator.predict(instance)\n",
      "    features = np.bincount(clusters)\n",
      "    if len(features) < n_clusters:\n",
      "        features = np.append(features, np.zeros((1, n_clusterslen(features))))\n",
      "    X_test.append(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#train logistic regression classifier on the feature vectors and targets\n",
      "#get precision, recall and accuracy of the model\n",
      "\n",
      "clf = LogisticRegression(C=0.001, penalty='l2')\n",
      "clf.fit_transform(X_train, y_train)\n",
      "predictions = clf.predict(X_test)\n",
      "print classification_report(y_test, predictions)\n",
      "print 'Precision: ', precision_score(y_test, predictions)\n",
      "print 'Recall: ', recall_score(y_test, predictions)\n",
      "print 'Accuracy: ', accuracy_score(y_test, predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#image processing is very data hungry,\n",
      "#unfortunately, python went out of memory while trying to fit KNN model on 4GB of RAM:-\n",
      "#obviously this model must be trained on a bigger RAM\n",
      "\n",
      "#in order to improve the model accuracy, intead of K=300 ,a bigger K value can be selected, but computation becomes more costly\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
